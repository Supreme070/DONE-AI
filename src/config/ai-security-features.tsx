
import { Shield, Brain, Cloud, Lock, Zap, Eye } from "lucide-react";

export const aiSecurityFeatures = [
  {
    title: "AI Model Security",
    description: "Comprehensive protection for machine learning models against adversarial attacks, model poisoning, and data extraction.",
    icon: Brain,
    image: "/lovable-uploads/c32c6788-5e4a-4fee-afee-604b03113c7f.png"
  },
  {
    title: "LLM Red Teaming",
    description: "Advanced testing framework for Large Language Models to identify vulnerabilities, prompt injection risks, and safety bypasses.",
    icon: Zap,
    image: "/lovable-uploads/7cc724d4-3e14-4e7c-9e7a-8d613fde54d0.png"
  },
  {
    title: "Cloud Infrastructure Protection",
    description: "Secure your AI cloud deployments with automated threat detection, compliance monitoring, and real-time security assessments.",
    icon: Cloud,
    image: "/lovable-uploads/86329743-ee49-4f2e-96f7-50508436273d.png"
  },
  {
    title: "Data Pipeline Security",
    description: "Protect your training data and inference pipelines with encryption, access controls, and integrity monitoring.",
    icon: Lock,
    image: "/lovable-uploads/bb50362c-6879-4868-bbc9-c6e051fd8d7d.png"
  },
  {
    title: "Threat Modeling & Intelligence",
    description: "AI-powered threat modeling with real-time intelligence feeds to anticipate and prevent emerging AI-specific attacks.",
    icon: Eye,
    image: "/lovable-uploads/bf56a0c6-48e4-49f7-b286-8e3fda9a3385.png"
  },
  {
    title: "Compliance & Governance",
    description: "Automated compliance reporting for AI regulations, governance frameworks, and industry standards like NIST AI RMF.",
    icon: Shield,
    image: "/lovable-uploads/b6436838-5c1a-419a-9cdc-1f9867df073d.png"
  }
];
